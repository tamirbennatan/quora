{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# import keras.backend as K\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import Embedding\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Merge\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers.merge import concatenate\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# import pickle as pkl\n",
    "\n",
    "# # import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese LSTM\n",
    "\n",
    "Here is an implementation of a Manhattan Siamese LSTM for the questiond deduplication problem. \n",
    "\n",
    "Siamese LSTMs are a deep neural network archetecture, where multiple inputs share the same LSTM strucuture and weights. \n",
    "\n",
    "A particular type of Siamese LSTM, caleld the Siamese Manhattan LSTM (MaLSTM) have been shown to be useful in learning Sentence Similarity, and are good learning semantic relationships between sentences [Mueller, Thyagarajan; 2016](http://www.mit.edu/~jonasm/info/MuellerThyagarajan_AAAI16.pdf)\n",
    "\n",
    "\n",
    "Here is a simple implementation of the Siamese Manhattan LSTM for the quora deduplication problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data and resources\n",
    "\n",
    "The data is already pre-processed in the preprocessing/string_cleaning.Rmd notebook.\n",
    "\n",
    "I've also trained a Tokenizer object on the entire dataset, which will allow me to convert sentences into index vectors - a format usable by neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor Koh - i - Noor D...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely ? How can I solv...</td>\n",
       "      <td>Find the remainder when math 23 24 math is div...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quickly sugar , sa...</td>\n",
       "      <td>Which fish would survive in salt water ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  qid1  qid2  \\\n",
       "0           1   0     1     2   \n",
       "1           2   1     3     4   \n",
       "2           3   2     5     6   \n",
       "3           4   3     7     8   \n",
       "4           5   4     9    10   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor Koh - i - Noor D...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely ? How can I solv...   \n",
       "4  Which one dissolve in water quickly sugar , sa...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when math 23 24 math is div...             0  \n",
       "4          Which fish would survive in salt water ?              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Load Tokenizer\n",
    "\n",
    "This converts sentences into index vectors in a consistent way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load pickled word tokenzier\n",
    "with open(\"../models/tokenizer.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93261"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of types in the joint datset\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[67, 3, 740, 19, 69, 6, 239, 378, 466, 184, 18065]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see if things look ok. 18065 is the index for <UNK>\n",
    "tokenizer.texts_to_sequences([\"this is text. It has a word never seen before. Namely: cockadoodledoo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A function for tokenizing, encoding and padding sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# A function which takes in a numpy array of quesitions (strings)\n",
    "# and returns padded index vectors usable by deep learning models. \n",
    "def encode_and_pad(questions, sequence_length = 25):\n",
    "    # questions encoded as index vectors\n",
    "    encoded = tokenizer.texts_to_sequences(questions)\n",
    "    # padded squences to be of length [sequence_length]\n",
    "    padded = pad_sequences(encoded, \n",
    "                            maxlen = sequence_length,\n",
    "                            padding = \"post\", \n",
    "                            truncating = \"post\")\n",
    "    return(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the pretrained fasttext embeddings (this takes a while)\n",
    "embedding_model = KeyedVectors.load_word2vec_format('../data/embeddings/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Each row in the matrix is the embedding of one word in the dataset. \n",
    "# The row index corresponds to the integer ecoding of that word. \n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embedding_model:\n",
    "        embedding_matrix[i] = embedding_model[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setting Up testing environment\n",
    "\n",
    "I spit the data into a training/dev/test split using a 60:20:20 split. \n",
    "\n",
    "The seed is set to `550` for consistency with my previous work and for future reproducability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets.\n",
    "X_train_and_dev, X_test, y_train_and_dev, y_test = train_test_split(\n",
    "    data[data.columns - [\"is_duplicate\"]], data['is_duplicate'], \\\n",
    "    test_size=0.2, random_state=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X_train_and_dev, y_train_and_dev, test_size=0.25, random_state=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404288, 7)\n",
      "\n",
      "(242572, 6)\n",
      "(80858, 6)\n",
      "(80858, 6)\n",
      "\n",
      "(242572,)\n",
      "(80858,)\n",
      "(80858,)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(data.shape)\n",
    "print\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)\n",
    "print \n",
    "print (y_train.shape)\n",
    "print(y_dev.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build Model Archetecutre\n",
    "\n",
    "Credit to Elior Cohen for [this awesome blog post!](https://medium.com/mlreview/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model specific parameters that dictate achetecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_HIDDEN_UNITS = 60\n",
    "N_EPOCHS = 25\n",
    "BATCH_SIZE = 64 #(404288 / 6317 )\n",
    "SEQUENCE_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need the Manhattan similarity function. This will be used for the merging layer: \n",
    "\n",
    "The Manhattan similarity between two vectors $v_1$ and $v_2$ is: \n",
    "$$\n",
    "ManhattanSim(v_1, v_2) = \\exp(-||{v_1 - v_2||_1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Credit Elior Cohen\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the input units - one for each question\n",
    "input1 = Input(shape=(SEQUENCE_LENGTH,), name=\"Question1-Input\")\n",
    "input2 = Input(shape=(SEQUENCE_LENGTH,), name=\"Question2-Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Embedding layer on top of first input \n",
    "embedding1 = Embedding(input_dim = vocab_size, \n",
    "                     output_dim = 300, \n",
    "                     input_length = SEQUENCE_LENGTH,\n",
    "                     trainable = False)(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Embedding layer on top of second input\n",
    "embedding2 = Embedding(input_dim = vocab_size, \n",
    "                     output_dim = 300, \n",
    "                     input_length = SEQUENCE_LENGTH,\n",
    "                     trainable = False)(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a shared LSTM unit. This is what makes it a Siamese LSTM\n",
    "shared_lstm = LSTM(N_HIDDEN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the outpouts of the two inputs, applied to the same LSTM unit\n",
    "left_output = shared_lstm(embedding1)\n",
    "right_output = shared_lstm(embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Merge the two outputs using Manhattan similarity \n",
    "merged = Merge(mode=lambda x:\\\n",
    "               exponent_neg_manhattan_distance(x[0], x[1]), \\\n",
    "               output_shape=lambda x: (x[0][0], 1))([left_output, right_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "MaLSTM = Model([input1, input2], [merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MaLSTM.compile(loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Question1-Input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Question2-Input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 300)      27978300    Question1-Input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 300)      27978300    Question2-Input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 60)           86640       embedding_2[0][0]                \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 1)            0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 56,043,240\n",
      "Trainable params: 86,640\n",
      "Non-trainable params: 55,956,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MaLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_model(MaLSTM, \"./diagrams/MaLSTM.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./diagrams/MaLSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MaLSTM.fit([X_train['question1'], X_train['question2']], y_train, \\\n",
    "           batch_size = BATCH_SIZE, nb_epoch = N_EPOCHS, \\\n",
    "           validation_data = ([X_validation['question1'], X_validation['question2']], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MaLSTM.save(\"../models/siamese_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
