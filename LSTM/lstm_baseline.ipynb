{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import Embedding\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers.merge import concatenate\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# import pickle as pkl\n",
    "\n",
    "# import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An LSTM Implementation for the quora question deduplication problem. \n",
    "\n",
    "Our goal for this project is to extend the previous work done on this problem by incorporating external knowledge and linguistic features. \n",
    "\n",
    "The current state-of-the-art solutions for this problem are almost unanimously deep recurrent network implementations. The best models can perform outstandingly well - better than human subjects (based on the result of over 500 responses I've collected from human subjects). \n",
    "\n",
    "Although our goal is to extract interesting linguistic insight rather to achieve competitive accuracy, if we are to claim that we've extended previous work, we must first build a model that is comparable to this work - both in accuracy and in technique. \n",
    "\n",
    "Thus, this model is intended to be a baseline performance model. What I would consider a success would be if we could make our other, less sophisticated (tree based) models as performant as this one, using hand crafted, insightful features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data and resources\n",
    "\n",
    "The data is already pre-processed in the `preprocessing/string_cleaning.Rmd` notebook. \n",
    "\n",
    "I've also trained a `Tokenizer` object on the entire dataset, which will allow me to convert sentences into index vectors - a format usable by neural network models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor Koh - i - Noor D...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely ? How can I solv...</td>\n",
       "      <td>Find the remainder when math 23 24 math is div...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quickly sugar , sa...</td>\n",
       "      <td>Which fish would survive in salt water ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  qid1  qid2  \\\n",
       "0           1   0     1     2   \n",
       "1           2   1     3     4   \n",
       "2           3   2     5     6   \n",
       "3           4   3     7     8   \n",
       "4           5   4     9    10   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor Koh - i - Noor D...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely ? How can I solv...   \n",
       "4  Which one dissolve in water quickly sugar , sa...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when math 23 24 math is div...             0  \n",
       "4          Which fish would survive in salt water ?              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Load Tokenizer\n",
    "\n",
    "This is pretrained `keras.preprocessing.text.Tokenizer` object, that will allow me convert sentenses to index vectors in a consistent way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pickled word tokenzier\n",
    "with open(\"../models/tokenizer.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[67, 3, 740, 19, 69, 6, 239, 378, 466, 184, 18065]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see if things look ok. 18065 is the index for <UNK>\n",
    "tokenizer.texts_to_sequences([\"this is text. It has a word never seen before. Namely: cockadoodledoo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the number of words encoded by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93261"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of types in the joint datset\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A function for tokenizing, indexing and padding sequences. \n",
    "\n",
    "Takes in sentences, outputs padded index vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function which takes in a numpy array of quesitions (strings)\n",
    "# and returns padded index vectors usable by deep learning models. \n",
    "def encode_and_pad(questions, sequence_length = 25):\n",
    "    # questions encoded as index vectors\n",
    "    encoded = tokenizer.texts_to_sequences(questions)\n",
    "    # padded squences to be of length [sequence_length]\n",
    "    padded = pad_sequences(encoded, \n",
    "                            maxlen = sequence_length,\n",
    "                            padding = \"post\", \n",
    "                            truncating = \"post\")\n",
    "    return(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  67,    3,   50, 2570,   19,    3,  667,    0,    0,    0],\n",
       "       [  67,    3,  403, 2570,   19,    3,   75, 1288,    8, 1475]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function\n",
    "encode_and_pad([\"this is one string. It is short,\",\n",
    "                \"this is another string. It is much longer. in fact, it is so long, that it should not be padded., \\\n",
    "                but rather it will be truncated. \"], \n",
    "              sequence_length = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load embedding matrix\n",
    "\n",
    "I use the pre-trained `fasttext` word embedding vectors (Mikolov, @Facebook Research). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the pretrained fasttext embeddings (this takes a while)\n",
    "embedding_model = KeyedVectors.load_word2vec_format('../data/embeddings/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each row in the matrix is the embedding of one word in the dataset. \n",
    "# The row index corresponds to the integer ecoding of that word. \n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embedding_model:\n",
    "        embedding_matrix[i] = embedding_model[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setting up testing environment\n",
    "\n",
    "To pick the right archetecture in a sincere way, I will need to split the data into training/developement/test sets. \n",
    "\n",
    "I'll split the data into test/developement/test using a 60:20:20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets.\n",
    "X_train_and_dev, X_test, y_train_and_dev, y_test = train_test_split(\n",
    "    data[data.columns - [\"is_duplicate\"]], data['is_duplicate'], \\\n",
    "    test_size=0.2, random_state=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X_train_and_dev, y_train_and_dev, test_size=0.25, random_state=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404288, 7)\n",
      "\n",
      "(242572, 6)\n",
      "(80858, 6)\n",
      "(80858, 6)\n",
      "\n",
      "(242572,)\n",
      "(80858,)\n",
      "(80858,)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(data.shape)\n",
    "print\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)\n",
    "print \n",
    "print (y_train.shape)\n",
    "print(y_dev.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. A first model\n",
    "\n",
    "This archetecture is inspired by that posted by Quora in [this block post](https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning) and [this great starter code](https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings) by the person who calls himself `lystdo` on Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for this model\n",
    "sequence_length1 = 25\n",
    "num_lstm1 = 200\n",
    "num_dense1 = 100\n",
    "dropout_rate1 = .2\n",
    "recurrent_droput_rate1 = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the input units - one for each question\n",
    "input1 = Input(shape=(sequence_length1,), name=\"Question1-Input\")\n",
    "input2 = Input(shape=(sequence_length1,), name=\"Question2-Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Embedding layer on top of first input \n",
    "embedding1 = Embedding(input_dim = vocab_size, \n",
    "                     output_dim = 300, \n",
    "                     input_length = sequence_length1,\n",
    "                     trainable = False)(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Embedding layer on top of second input\n",
    "embedding2 = Embedding(input_dim = vocab_size, \n",
    "                     output_dim = 300, \n",
    "                     input_length = sequence_length1,\n",
    "                     trainable = False)(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add an LSTM unit to first input path\n",
    "lstm_unit1 = LSTM(num_lstm1, dropout = dropout_rate1, recurrent_dropout = recurrent_droput_rate1)(embedding1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add an LSTM unit to the second input path\n",
    "lstm_unit2 = LSTM(num_lstm1, dropout = dropout_rate1, recurrent_dropout = recurrent_droput_rate1)(embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge the two streams in to one \n",
    "merged = concatenate([lstm_unit1,lstm_unit2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add some dropout and some normalization, which will help speed up convergence. \n",
    "merged = Dropout(dropout_rate1)(merged)\n",
    "merged = BatchNormalization()(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a fully connected layer with ReLU acivation, to hold onto long dependencies\n",
    "merged = Dense(num_dense1, activation='relu')(merged)\n",
    "merged = Dropout(dropout_rate1)(merged)\n",
    "merged = BatchNormalization()(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finally add a dense output layer with a sigmoid activation \n",
    "predictions = Dense(1, activation='sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make sure things are OK, I'll compile the mode, look at the structure and diagram of the archetecrure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Model(inputs=[input1, input2], \\\n",
    "        outputs=predictions)\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Question1-Input (InputLayer)    (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Question2-Input (InputLayer)    (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 25, 300)      27978300    Question1-Input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 25, 300)      27978300    Question2-Input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 200)          400800      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 200)          400800      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 400)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400)          1600        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          40100       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100)          400         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 56,800,401\n",
      "Trainable params: 842,801\n",
      "Non-trainable params: 55,957,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_model(model1, \"./diagrams/model1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](diagrams/model1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll add Early Stopping, so that the model will stop training if the developement error doesn't improve for 3 straight epochs. \n",
    "\n",
    "I'll also save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\"../models/lstm1.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isolate the training and developement data/labels\n",
    "question1_train = X_train['question1'].values\n",
    "question2_train = X_train['question2'].values\n",
    "\n",
    "question1_dev = X_dev['question1'].values\n",
    "question2_dev = X_dev['question2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242572 samples, validate on 80858 samples\n",
      "Epoch 1/200\n",
      "242572/242572 [==============================] - 958s 4ms/step - loss: 0.6791 - acc: 0.5964 - val_loss: 0.6433 - val_acc: 0.6311\n",
      "Epoch 2/200\n",
      "242572/242572 [==============================] - 919s 4ms/step - loss: 0.6192 - acc: 0.6448 - val_loss: 0.6717 - val_acc: 0.5658\n",
      "Epoch 3/200\n",
      "242572/242572 [==============================] - 981s 4ms/step - loss: 0.5877 - acc: 0.6826 - val_loss: 0.5983 - val_acc: 0.6711\n",
      "Epoch 4/200\n",
      "242572/242572 [==============================] - 24294s 100ms/step - loss: 0.5759 - acc: 0.6930 - val_loss: 0.5911 - val_acc: 0.6857\n",
      "Epoch 5/200\n",
      "242572/242572 [==============================] - 901s 4ms/step - loss: 0.5693 - acc: 0.6985 - val_loss: 0.6199 - val_acc: 0.6352\n",
      "Epoch 6/200\n",
      "242572/242572 [==============================] - 893s 4ms/step - loss: 0.5625 - acc: 0.7036 - val_loss: 0.5876 - val_acc: 0.6817\n",
      "Epoch 7/200\n",
      "242572/242572 [==============================] - 895s 4ms/step - loss: 0.5579 - acc: 0.7078 - val_loss: 0.5946 - val_acc: 0.6647\n",
      "Epoch 8/200\n",
      "242572/242572 [==============================] - 916s 4ms/step - loss: 0.5532 - acc: 0.7107 - val_loss: 0.5634 - val_acc: 0.7084\n",
      "Epoch 9/200\n",
      "242572/242572 [==============================] - 899s 4ms/step - loss: 0.5489 - acc: 0.7134 - val_loss: 0.5627 - val_acc: 0.6986\n",
      "Epoch 10/200\n",
      "242572/242572 [==============================] - 898s 4ms/step - loss: 0.5448 - acc: 0.7169 - val_loss: 0.5520 - val_acc: 0.7140\n",
      "Epoch 11/200\n",
      "242572/242572 [==============================] - 901s 4ms/step - loss: 0.5406 - acc: 0.7196 - val_loss: 0.6069 - val_acc: 0.6921\n",
      "Epoch 12/200\n",
      "242572/242572 [==============================] - 895s 4ms/step - loss: 0.5362 - acc: 0.7234 - val_loss: 0.5617 - val_acc: 0.7053\n",
      "Epoch 13/200\n",
      "242572/242572 [==============================] - 892s 4ms/step - loss: 0.5322 - acc: 0.7258 - val_loss: 0.5531 - val_acc: 0.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235c7c290>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, with early stopping\n",
    "model1.fit([encode_and_pad(question1_train), encode_and_pad(question2_train)], y_train, \\\n",
    "        validation_data=([encode_and_pad(question1_dev), encode_and_pad(question2_dev)], y_dev), \\\n",
    "        epochs=200, batch_size=2425, shuffle=False, \\\n",
    "        callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
