{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named np_utils",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-6b82421ee98f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# from sklearn.metrics import accuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# from keras.metrics import binary_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprobas_to_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# from gensim.models import KeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named np_utils"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# import keras.backend as K\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import Embedding\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Merge\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers.merge import concatenate\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from keras.metrics import binary_accuracy\n",
    "from keras.np_utils import probas_to_classes\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# import pickle as pkl\n",
    "\n",
    "# import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese LSTM\n",
    "\n",
    "Here is an implementation of a Manhattan Siamese LSTM for the questiond deduplication problem. \n",
    "\n",
    "Siamese LSTMs are a deep neural network archetecture, where multiple inputs share the same LSTM strucuture and weights. \n",
    "\n",
    "A particular type of Siamese LSTM, caleld the Siamese Manhattan LSTM (MaLSTM) have been shown to be useful in learning Sentence Similarity, and are good learning semantic relationships between sentences [Mueller, Thyagarajan; 2016](http://www.mit.edu/~jonasm/info/MuellerThyagarajan_AAAI16.pdf)\n",
    "\n",
    "\n",
    "Here is a simple implementation of the Siamese Manhattan LSTM for the quora deduplication problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data and resources\n",
    "\n",
    "The data is already pre-processed in the preprocessing/string_cleaning.Rmd notebook.\n",
    "\n",
    "I've also trained a Tokenizer object on the entire dataset, which will allow me to convert sentences into index vectors - a format usable by neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor Koh - i - Noor D...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely ? How can I solv...</td>\n",
       "      <td>Find the remainder when math 23 24 math is div...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quickly sugar , sa...</td>\n",
       "      <td>Which fish would survive in salt water ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  qid1  qid2  \\\n",
       "0           1   0     1     2   \n",
       "1           2   1     3     4   \n",
       "2           3   2     5     6   \n",
       "3           4   3     7     8   \n",
       "4           5   4     9    10   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor Koh - i - Noor D...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely ? How can I solv...   \n",
       "4  Which one dissolve in water quickly sugar , sa...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when math 23 24 math is div...             0  \n",
       "4          Which fish would survive in salt water ?              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Load Tokenizer\n",
    "\n",
    "This converts sentences into index vectors in a consistent way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load pickled word tokenzier\n",
    "with open(\"../models/tokenizer.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93261"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of types in the joint datset\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[67, 3, 740, 19, 69, 6, 239, 378, 466, 184, 18065]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see if things look ok. 18065 is the index for <UNK>\n",
    "tokenizer.texts_to_sequences([\"this is text. It has a word never seen before. Namely: cockadoodledoo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A function for tokenizing, encoding and padding sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# A function which takes in a numpy array of quesitions (strings)\n",
    "# and returns padded index vectors usable by deep learning models. \n",
    "def encode_and_pad(questions, sequence_length = 25):\n",
    "    # questions encoded as index vectors\n",
    "    encoded = tokenizer.texts_to_sequences(questions)\n",
    "    # padded squences to be of length [sequence_length]\n",
    "    padded = pad_sequences(encoded, \n",
    "                            maxlen = sequence_length,\n",
    "                            padding = \"post\", \n",
    "                            truncating = \"post\")\n",
    "    return(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the pretrained fasttext embeddings (this takes a while)\n",
    "embedding_model = KeyedVectors.load_word2vec_format('../data/embeddings/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Each row in the matrix is the embedding of one word in the dataset. \n",
    "# The row index corresponds to the integer ecoding of that word. \n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embedding_model:\n",
    "        embedding_matrix[i] = embedding_model[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setting Up testing environment\n",
    "\n",
    "I spit the data into a training/dev/test split using a 60:20:20 split. \n",
    "\n",
    "The seed is set to `550` for consistency with my previous work and for future reproducability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets.\n",
    "X_train_and_dev, X_test, y_train_and_dev, y_test = train_test_split(\n",
    "    data[data.columns - [\"is_duplicate\"]], data['is_duplicate'], \\\n",
    "    test_size=0.2, random_state=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X_train_and_dev, y_train_and_dev, test_size=0.25, random_state=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404288, 7)\n",
      "\n",
      "(242572, 6)\n",
      "(80858, 6)\n",
      "(80858, 6)\n",
      "\n",
      "(242572,)\n",
      "(80858,)\n",
      "(80858,)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(data.shape)\n",
    "print\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)\n",
    "print \n",
    "print (y_train.shape)\n",
    "print(y_dev.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build Model Archetecutre\n",
    "\n",
    "Credit to Elior Cohen for [this awesome blog post!](https://medium.com/mlreview/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model specific parameters that dictate achetecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_HIDDEN_UNITS = 60\n",
    "N_EPOCHS = 25\n",
    "BATCH_SIZE = 64 #(404288 / 6317 )\n",
    "SEQUENCE_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need the Manhattan similarity function. This will be used for the merging layer: \n",
    "\n",
    "The Manhattan similarity between two vectors $v_1$ and $v_2$ is: \n",
    "$$\n",
    "ManhattanSim(v_1, v_2) = \\exp(-||{v_1 - v_2||_1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Credit Elior Cohen\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the input units - one for each question\n",
    "input1 = Input(shape=(SEQUENCE_LENGTH,), name=\"Question1-Input\")\n",
    "input2 = Input(shape=(SEQUENCE_LENGTH,), name=\"Question2-Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Embedding layer on top of first input \n",
    "embedding1 = Embedding(input_dim = vocab_size, \n",
    "                     output_dim = 300, \n",
    "                     input_length = SEQUENCE_LENGTH,\n",
    "                     trainable = False)(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Embedding layer on top of second input\n",
    "embedding2 = Embedding(input_dim = vocab_size, \n",
    "                     output_dim = 300, \n",
    "                     input_length = SEQUENCE_LENGTH,\n",
    "                     trainable = False)(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a shared LSTM unit. This is what makes it a Siamese LSTM\n",
    "shared_lstm = LSTM(N_HIDDEN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the outpouts of the two inputs, applied to the same LSTM unit\n",
    "left_output = shared_lstm(embedding1)\n",
    "right_output = shared_lstm(embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Merge the two outputs using Manhattan similarity \n",
    "merged = Merge(mode=lambda x:\\\n",
    "               exponent_neg_manhattan_distance(x[0], x[1]), \\\n",
    "               output_shape=lambda x: (x[0][0], 1))([left_output, right_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "MaLSTM = Model([input1, input2], [merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MaLSTM.compile(loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Question1-Input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Question2-Input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 300)      27978300    Question1-Input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 300)      27978300    Question2-Input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 60)           86640       embedding_2[0][0]                \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 1)            0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 56,043,240\n",
      "Trainable params: 86,640\n",
      "Non-trainable params: 55,956,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MaLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_model(MaLSTM, \"./diagrams/MaLSTM.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./diagrams/MaLSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isolate the training and developement data/labels\n",
    "question1_train = X_train['question1'].values\n",
    "question2_train = X_train['question2'].values\n",
    "\n",
    "question1_dev = X_dev['question1'].values\n",
    "question2_dev = X_dev['question2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242572 samples, validate on 80858 samples\n",
      "Epoch 1/25\n",
      "242572/242572 [==============================] - 549s 2ms/step - loss: 0.6068 - acc: 0.6549 - val_loss: 0.5696 - val_acc: 0.6999\n",
      "Epoch 2/25\n",
      "242572/242572 [==============================] - 536s 2ms/step - loss: 0.5582 - acc: 0.7103 - val_loss: 0.5632 - val_acc: 0.7032\n",
      "Epoch 3/25\n",
      "242572/242572 [==============================] - 529s 2ms/step - loss: 0.5399 - acc: 0.7248 - val_loss: 0.5391 - val_acc: 0.7235\n",
      "Epoch 4/25\n",
      "242572/242572 [==============================] - 526s 2ms/step - loss: 0.5248 - acc: 0.7352 - val_loss: 0.5332 - val_acc: 0.7322\n",
      "Epoch 5/25\n",
      "242572/242572 [==============================] - 525s 2ms/step - loss: 0.5117 - acc: 0.7456 - val_loss: 0.5221 - val_acc: 0.7387\n",
      "Epoch 6/25\n",
      "242572/242572 [==============================] - 462s 2ms/step - loss: 0.4981 - acc: 0.7548 - val_loss: 0.5156 - val_acc: 0.7416\n",
      "Epoch 7/25\n",
      "242572/242572 [==============================] - 466s 2ms/step - loss: 0.4864 - acc: 0.7631 - val_loss: 0.5112 - val_acc: 0.7467\n",
      "Epoch 8/25\n",
      "242572/242572 [==============================] - 453s 2ms/step - loss: 0.4748 - acc: 0.7712 - val_loss: 0.5127 - val_acc: 0.7489\n",
      "Epoch 9/25\n",
      "242572/242572 [==============================] - 461s 2ms/step - loss: 0.4630 - acc: 0.7795 - val_loss: 0.5017 - val_acc: 0.7565\n",
      "Epoch 10/25\n",
      "242572/242572 [==============================] - 458s 2ms/step - loss: 0.4527 - acc: 0.7854 - val_loss: 0.4999 - val_acc: 0.7579\n",
      "Epoch 11/25\n",
      "242572/242572 [==============================] - 458s 2ms/step - loss: 0.4429 - acc: 0.7920 - val_loss: 0.5018 - val_acc: 0.7592\n",
      "Epoch 12/25\n",
      "242572/242572 [==============================] - 457s 2ms/step - loss: 0.4332 - acc: 0.7982 - val_loss: 0.5028 - val_acc: 0.7572\n",
      "Epoch 13/25\n",
      "242572/242572 [==============================] - 512s 2ms/step - loss: 0.4235 - acc: 0.8041 - val_loss: 0.5061 - val_acc: 0.7577\n",
      "Epoch 14/25\n",
      "242572/242572 [==============================] - 524s 2ms/step - loss: 0.4145 - acc: 0.8082 - val_loss: 0.5003 - val_acc: 0.7603\n",
      "Epoch 15/25\n",
      "242572/242572 [==============================] - 524s 2ms/step - loss: 0.4062 - acc: 0.8137 - val_loss: 0.5063 - val_acc: 0.7582\n",
      "Epoch 16/25\n",
      "242572/242572 [==============================] - 529s 2ms/step - loss: 0.3975 - acc: 0.8185 - val_loss: 0.5206 - val_acc: 0.7540\n",
      "Epoch 17/25\n",
      "242572/242572 [==============================] - 524s 2ms/step - loss: 0.3904 - acc: 0.8226 - val_loss: 0.5206 - val_acc: 0.7584\n",
      "Epoch 18/25\n",
      "242572/242572 [==============================] - 529s 2ms/step - loss: 0.3834 - acc: 0.8262 - val_loss: 0.5226 - val_acc: 0.7598\n",
      "Epoch 19/25\n",
      "242572/242572 [==============================] - 489s 2ms/step - loss: 0.3753 - acc: 0.8303 - val_loss: 0.5293 - val_acc: 0.7550\n",
      "Epoch 20/25\n",
      "242572/242572 [==============================] - 465s 2ms/step - loss: 0.3696 - acc: 0.8344 - val_loss: 0.5258 - val_acc: 0.7584\n",
      "Epoch 21/25\n",
      "242572/242572 [==============================] - 465s 2ms/step - loss: 0.3624 - acc: 0.8373 - val_loss: 0.5311 - val_acc: 0.7555\n",
      "Epoch 22/25\n",
      "242572/242572 [==============================] - 464s 2ms/step - loss: 0.3579 - acc: 0.8402 - val_loss: 0.5468 - val_acc: 0.7577\n",
      "Epoch 23/25\n",
      "242572/242572 [==============================] - 460s 2ms/step - loss: 0.3516 - acc: 0.8435 - val_loss: 0.5425 - val_acc: 0.7597\n",
      "Epoch 24/25\n",
      "242572/242572 [==============================] - 465s 2ms/step - loss: 0.3463 - acc: 0.8457 - val_loss: 0.5439 - val_acc: 0.7586\n",
      "Epoch 25/25\n",
      "242572/242572 [==============================] - 514s 2ms/step - loss: 0.3409 - acc: 0.8486 - val_loss: 0.5582 - val_acc: 0.7559\n"
     ]
    }
   ],
   "source": [
    "trained = MaLSTM.fit([encode_and_pad(question1_train, SEQUENCE_LENGTH), encode_and_pad(question2_train, SEQUENCE_LENGTH)], y_train,\n",
    "           batch_size = BATCH_SIZE, nb_epoch = N_EPOCHS, \\\n",
    "           validation_data = ([encode_and_pad(question1_dev, SEQUENCE_LENGTH), encode_and_pad(question2_dev, SEQUENCE_LENGTH)], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MaLSTM.save(\"../models/siamese_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isolate the training and developement data/labels\n",
    "question1_test = X_test['question1'].values\n",
    "question2_test = X_test['question2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Question1-Input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Question2-Input (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 300)      27978300    Question1-Input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 300)      27978300    Question2-Input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 60)           86640       embedding_2[0][0]                \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 1)            0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 56,043,240\n",
      "Trainable params: 86,640\n",
      "Non-trainable params: 55,956,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MaLSTM.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred = MaLSTM.predict([encode_and_pad(question1_test, SEQUENCE_LENGTH), encode_and_pad(question2_test, SEQUENCE_LENGTH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75886121348536939"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.values.astype(np.float32), np.round(test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
