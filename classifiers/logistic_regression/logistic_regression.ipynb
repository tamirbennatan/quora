{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.grid_search import GridSearchCV  \n",
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier\n",
    "\n",
    "Here, I implement a simple logistic regression classifier to the different feature groups that I am experimenting with (described more in `xgboost/xgboost_extended_features`. \n",
    "\n",
    "I am by no means tuning this model as best I can - I do not expect a logistic regression to be able to learn functions complex enough to solve this problem well. I am doing this so that I can have a baseline to compare my more advanced ensemble tree classifeirs with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>...</th>\n",
       "      <th>lstm_2_q2_pred</th>\n",
       "      <th>lstm_3_q1_pred</th>\n",
       "      <th>lstm_3_q2_pred</th>\n",
       "      <th>lstm_4_q1_pred</th>\n",
       "      <th>lstm_4_q2_pred</th>\n",
       "      <th>lstm_5_q1_pred</th>\n",
       "      <th>lstm_5_q2_pred</th>\n",
       "      <th>lstm_vote_q1</th>\n",
       "      <th>lstm_vote_q2</th>\n",
       "      <th>lstm_vote_agree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor Koh - i - Noor D...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely ? How can I solv...</td>\n",
       "      <td>Find the remainder when math 23 24 math is div...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quickly sugar , sa...</td>\n",
       "      <td>Which fish would survive in salt water ?</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1  Unnamed: 0.1.1  id  qid1  qid2  \\\n",
       "0           0             1             1               1   0     1     2   \n",
       "1           1             2             2               2   1     3     4   \n",
       "2           2             3             3               3   2     5     6   \n",
       "3           3             4             4               4   3     7     8   \n",
       "4           4             5             5               5   4     9    10   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor Koh - i - Noor D...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely ? How can I solv...   \n",
       "4  Which one dissolve in water quickly sugar , sa...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when math 23 24 math is div...             0   \n",
       "4          Which fish would survive in salt water ?              0   \n",
       "\n",
       "        ...         lstm_2_q2_pred  lstm_3_q1_pred  lstm_3_q2_pred  \\\n",
       "0       ...                      2               1               1   \n",
       "1       ...                      2               1               3   \n",
       "2       ...                      1               1               1   \n",
       "3       ...                      5               1               5   \n",
       "4       ...                      2               2               2   \n",
       "\n",
       "   lstm_4_q1_pred  lstm_4_q2_pred  lstm_5_q1_pred  lstm_5_q2_pred  \\\n",
       "0               2               2               1               1   \n",
       "1               2               1               5               1   \n",
       "2               1               1               1               1   \n",
       "3               1               1               1               5   \n",
       "4               2               2               3               2   \n",
       "\n",
       "   lstm_vote_q1  lstm_vote_q2  lstm_vote_agree  \n",
       "0             1             1             True  \n",
       "1             2             1            False  \n",
       "2             1             1             True  \n",
       "3             1             5            False  \n",
       "4             3             2            False  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Experimental setups\n",
    "\n",
    "I'll split the data into train/test sets, using a 80:20 split. I will be usin 3-fold cross validation fo hyper-parameter tuning. As usual, I set my random seed to `550` everywhere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != \"is_duplicate\"]\n",
    "labels = data['is_duplicate'].values\n",
    "\n",
    "# Split data into training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[features], labels, test_size=0.2, random_state=550, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404288, 68)\n",
      "\n",
      "(323430, 69)\n",
      "(80858, 69)\n",
      "\n",
      "(323430,)\n",
      "(80858,)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(data.shape)\n",
    "print\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0.1', u'Unnamed: 0.1', u'Unnamed: 0.1.1', u'id'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0.1', u'Unnamed: 0.1', u'Unnamed: 0.1', u'Unnamed: 0.1'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason there is an extra column in the training data than in the original column is that when splitting an extra two columns named `Unnamed` were added.\n",
    "\n",
    "That's annoying. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Features to train on\n",
    "\n",
    "Here are the different feature groups I will test and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all features\n",
    "all_features = [u'len_intersection',\n",
    "                 u'num_words_q1',\n",
    "                 u'num_words_q2',\n",
    "                 u'num_chars_q1',\n",
    "                 u'num_chars_q2',\n",
    "                 u'num_chars_diff',\n",
    "                 u'partial_ratio',\n",
    "                 u'partial_ratio_sw',\n",
    "                 u'token_set_ratio',\n",
    "                 u'token_set_ratio_sw',\n",
    "                 u'partial_token_sort_ratio_sw',\n",
    "                 u'wratio_sw',\n",
    "                 u'word_intersection_tfidf_weight',\n",
    "                 u'word_symmetric_difference_tfidf_weight',\n",
    "                 u'euclidean_distance_sentence_embeddings',\n",
    "                 u'cosine_distance_sentence_embeddings',\n",
    "                 u'cityblock_distance_sentence_embeddings',\n",
    "                 u'braycurtis_distance_sentence_embeddings',\n",
    "                 u'euclidean_distance_max_tfidf_word',\n",
    "                 u'cosine_distance_max_tfidf_word',\n",
    "                 u'lch_similarity',\n",
    "                 u'embedding_similarity_score', \n",
    "                 'lstm_vote_q1', \n",
    "                 'lstm_vote_q2',\n",
    "                 'lstm_vote_agree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Excluding TF-IDF features\n",
    "no_tfidf = [u'len_intersection',\n",
    "                 u'num_words_q1',\n",
    "                 u'num_words_q2',\n",
    "                 u'num_chars_q1',\n",
    "                 u'num_chars_q2',\n",
    "                 u'num_chars_diff',\n",
    "                 u'partial_ratio',\n",
    "                 u'partial_ratio_sw',\n",
    "                 u'token_set_ratio',\n",
    "                 u'token_set_ratio_sw',\n",
    "                 u'partial_token_sort_ratio_sw',\n",
    "                 u'wratio_sw',\n",
    "                 u'euclidean_distance_sentence_embeddings',\n",
    "                 u'cosine_distance_sentence_embeddings',\n",
    "                 u'cityblock_distance_sentence_embeddings',\n",
    "                 u'braycurtis_distance_sentence_embeddings',\n",
    "                 u'lch_similarity',\n",
    "                 u'embedding_similarity_score', \n",
    "                 'lstm_vote_q1', \n",
    "                 'lstm_vote_q2',\n",
    "                 'lstm_vote_agree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Excluding similarity scores\n",
    "no_similarity_scores = [u'len_intersection',\n",
    "                 u'num_words_q1',\n",
    "                 u'num_words_q2',\n",
    "                 u'num_chars_q1',\n",
    "                 u'num_chars_q2',\n",
    "                 u'num_chars_diff',\n",
    "                 u'partial_ratio',\n",
    "                 u'partial_ratio_sw',\n",
    "                 u'token_set_ratio',\n",
    "                 u'token_set_ratio_sw',\n",
    "                 u'partial_token_sort_ratio_sw',\n",
    "                 u'wratio_sw',\n",
    "                 u'word_intersection_tfidf_weight',\n",
    "                 u'word_symmetric_difference_tfidf_weight',\n",
    "                 u'euclidean_distance_sentence_embeddings',\n",
    "                 u'cosine_distance_sentence_embeddings',\n",
    "                 u'cityblock_distance_sentence_embeddings',\n",
    "                 u'braycurtis_distance_sentence_embeddings',\n",
    "                 u'euclidean_distance_max_tfidf_word',\n",
    "                 u'cosine_distance_max_tfidf_word',\n",
    "                'lstm_vote_q1', \n",
    "                 'lstm_vote_q2',\n",
    "                 'lstm_vote_agree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No TREC features\n",
    "no_trec = [u'len_intersection',\n",
    "                 u'num_words_q1',\n",
    "                 u'num_words_q2',\n",
    "                 u'num_chars_q1',\n",
    "                 u'num_chars_q2',\n",
    "                 u'num_chars_diff',\n",
    "                 u'partial_ratio',\n",
    "                 u'partial_ratio_sw',\n",
    "                 u'token_set_ratio',\n",
    "                 u'token_set_ratio_sw',\n",
    "                 u'partial_token_sort_ratio_sw',\n",
    "                 u'wratio_sw',\n",
    "                 u'word_intersection_tfidf_weight',\n",
    "                 u'word_symmetric_difference_tfidf_weight',\n",
    "                 u'euclidean_distance_sentence_embeddings',\n",
    "                 u'cosine_distance_sentence_embeddings',\n",
    "                 u'cityblock_distance_sentence_embeddings',\n",
    "                 u'braycurtis_distance_sentence_embeddings',\n",
    "                 u'euclidean_distance_max_tfidf_word',\n",
    "                 u'cosine_distance_max_tfidf_word',\n",
    "                 u'lch_similarity',\n",
    "                 u'embedding_similarity_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similarity or tfidf\n",
    "no_similarity_or_tfidf = list(set(no_similarity_scores).intersection(set(no_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No similarity or trec\n",
    "no_similarity_or_trec = list(set(no_similarity_scores).intersection(set(no_trec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no tfidf or trec\n",
    "no_tfidf_or_trec = list(set(no_tfidf).intersection(no_trec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no extra features\n",
    "no_extra_features = list(set(no_tfidf_or_trec).intersection(set(no_similarity_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Determining the regularization parameter `C`. \n",
    "\n",
    "The only parameter tuning that I will do is with the regularization term, $C = \\frac{1}{\\lambda}$. I will only get to the precision of a power of 10, since I'm not expecting (or trying) to get great performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters to serach through\n",
    "C_grid = {\"C\": [1e-2, 1e-1, 1, 1e2, 1e3, 1e4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a vanilla logistic regression (with regularization)\n",
    "model_full = LogisticRegression(random_state = 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_grid_search = GridSearchCV(estimator = model_full, param_grid = C_grid,  n_jobs = -1, \\\n",
    "                                scoring= \"neg_log_loss\", cv = 3, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] .................... C=0.01, score=-0.532362371105, total=  27.6s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] .................... C=0.01, score=-0.531210507564, total=  27.6s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] .................... C=0.01, score=-0.532734558122, total=  29.4s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ..................... C=0.1, score=-0.525532774716, total=  42.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ..................... C=0.1, score=-0.525737471425, total=  28.8s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ..................... C=0.1, score=-0.523853938403, total=  32.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ....................... C=1, score=-0.524781724866, total=  37.3s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ....................... C=1, score=-0.523012269071, total=  39.9s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ................... C=100.0, score=-0.524734606128, total=  33.4s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ................... C=100.0, score=-0.523304500198, total=  28.9s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ....................... C=1, score=-0.524960472934, total=  40.9s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] .................. C=1000.0, score=-0.524705167987, total=  37.2s\n",
      "[CV] C=10000.0 .......................................................\n",
      "[CV] .................. C=1000.0, score=-0.524977383515, total=  34.4s\n",
      "[CV] C=10000.0 .......................................................\n",
      "[CV] .................... C=100.0, score=-0.52484400822, total=  52.1s\n",
      "[CV] C=10000.0 .......................................................\n",
      "[CV] .................. C=1000.0, score=-0.522962510299, total=  39.1s\n",
      "[CV] ................. C=10000.0, score=-0.525049890419, total=  24.3s\n",
      "[CV] .................. C=10000.0, score=-0.52478383495, total=  28.8s\n",
      "[CV] ................. C=10000.0, score=-0.522936067676, total=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "# search through the different regularization values. \n",
    "full_grid_result = full_grid_search.fit(X_train[all_features], y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest value of `C` was chosen - which means an even higher value might be prefered. I'll run it again using higher regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters to serach through\n",
    "C_grid = {\"C\": [1e4, 1e5, 1e6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_grid_search = GridSearchCV(estimator = model_full, param_grid = C_grid,  n_jobs = -1, \\\n",
    "                                scoring= \"neg_log_loss\", cv = 3, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] C=10000.0 .......................................................\n",
      "[CV] C=10000.0 .......................................................\n",
      "[CV] C=10000.0 .......................................................\n",
      "[CV] C=100000.0 ......................................................\n",
      "[CV] ................ C=100000.0, score=-0.524688920246, total=  44.9s\n",
      "[CV] C=100000.0 ......................................................\n",
      "[CV] ................. C=10000.0, score=-0.524872247639, total=  49.3s\n",
      "[CV] C=100000.0 ......................................................\n",
      "[CV] .................. C=10000.0, score=-0.52461356948, total=  49.9s\n",
      "[CV] C=1000000.0 .....................................................\n",
      "[CV] ................. C=10000.0, score=-0.522934089239, total=  50.9s\n",
      "[CV] C=1000000.0 .....................................................\n",
      "[CV] ............... C=1000000.0, score=-0.522940816562, total=  34.0s\n",
      "[CV] C=1000000.0 .....................................................\n",
      "[CV] ................ C=100000.0, score=-0.525033278336, total=  36.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:  1.5min remaining:   44.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000000.0, score=-0.524709348239, total=  43.1s\n",
      "[CV] ................ C=100000.0, score=-0.522937767939, total=  48.0s\n",
      "[CV] ............... C=1000000.0, score=-0.525446749697, total=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "# search through the different regularization values. \n",
    "full_grid_result = full_grid_search.fit(X_train[all_features], y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training models and testing on Test set. \n",
    "\n",
    "Now that we have that the regularziation parameter should be in the neighborhood of `10000`, I will train the logistic regression on the different subsets of the data. \n",
    "\n",
    "Note: as I am not doing any more parameter tuning, I will not be using a developement set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "model_full = LogisticRegression(C=10000, n_jobs= -1, random_state = 550).fit(X_train[all_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6962576368448391"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test error\n",
    "accuracy_score(y_test, model_full.predict(X_test[all_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7549    0.7710    0.7628     51235\n",
      "          1     0.5887    0.5671    0.5777     29623\n",
      "\n",
      "avg / total     0.6940    0.6963    0.6950     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_full.predict(X_test[all_features]), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no tfidf scores\n",
    "model_no_tfidf = LogisticRegression(C=10000, random_state = 550).fit(X_train[no_tfidf], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68384080734126496"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_no_tfidf.predict(X_test[no_tfidf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7408    0.7707    0.7555     51235\n",
      "          1     0.5736    0.5336    0.5529     29623\n",
      "\n",
      "avg / total     0.6796    0.6838    0.6813     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_no_tfidf.predict(X_test[no_tfidf]), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No similarity scores\n",
    "model_no_similiarity_scores = LogisticRegression(C=10000, random_state = 550).fit(X_train[no_similarity_scores], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68377897054094838"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_no_similiarity_scores.predict(X_test[no_similarity_scores]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7412    0.7697    0.7552     51235\n",
      "          1     0.5733    0.5351    0.5536     29623\n",
      "\n",
      "avg / total     0.6797    0.6838    0.6813     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_no_similiarity_scores.predict(X_test[no_similarity_scores]),\n",
    "                            digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No TREC predictions\n",
    "model_no_trec = LogisticRegression(C=10000, random_state = 550).fit(X_train[no_trec], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69510747235895021"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_no_trec.predict(X_test[no_trec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7537    0.7706    0.7621     51235\n",
      "          1     0.5873    0.5645    0.5756     29623\n",
      "\n",
      "avg / total     0.6927    0.6951    0.6938     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_no_trec.predict(X_test[no_trec]), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No TFIDF or Similarity Scores\n",
    "model_no_similarity_or_tfidf = LogisticRegression(C=10000, random_state = 550).fit(X_train[no_similarity_or_tfidf], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67434267481263455"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_no_similarity_or_tfidf.predict(X_test[no_similarity_or_tfidf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7302    0.7710    0.7500     51235\n",
      "          1     0.5615    0.5072    0.5330     29623\n",
      "\n",
      "avg / total     0.6684    0.6743    0.6705     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_no_similarity_or_tfidf.predict(X_test[no_similarity_or_tfidf]), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No TF-IDF or TREC\n",
    "model_no_tfidf_or_trec = LogisticRegression(C=10000, random_state = 550).fit(X_train[no_tfidf_or_trec], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68363056222018848"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_no_tfidf_or_trec.predict(X_test[no_tfidf_or_trec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7407    0.7703    0.7552     51235\n",
      "          1     0.5733    0.5337    0.5528     29623\n",
      "\n",
      "avg / total     0.6794    0.6836    0.6811     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_no_tfidf_or_trec.predict(X_test[no_tfidf_or_trec]), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No similarity or TREC\n",
    "model_no_similarity_or_trec = LogisticRegression(C=10000, random_state = 550).fit(X_train[no_similarity_or_trec], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68270301021543944"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_no_similarity_or_trec.predict(X_test[no_similarity_or_trec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7397    0.7704    0.7547     51235\n",
      "          1     0.5721    0.5311    0.5508     29623\n",
      "\n",
      "avg / total     0.6783    0.6827    0.6800     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_no_similarity_or_trec.predict(X_test[no_similarity_or_trec]), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No extra features\n",
    "model_no_extra_features =  LogisticRegression(C=10000, random_state = 550).fit(X_train[no_extra_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67279675480471934"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_no_extra_features.predict(X_test[no_extra_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7287    0.7705    0.7490     51235\n",
      "          1     0.5593    0.5038    0.5301     29623\n",
      "\n",
      "avg / total     0.6666    0.6728    0.6688     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_no_extra_features.predict(X_test[no_extra_features]), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a random baseline which predicts zero or one with equal probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50148408320759852"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(550)\n",
    "accuracy_score(y_test, np.random.randint(2, size = y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_names = [\"all_features\", \"no_similarity_scores\", \"no_tfidf\", \"no_trec\", \"no_similarity_or_tfidf\", \\\n",
    "       \"no_similarity_or_trec\", \"no_tfidf_or_trec\", \"no_extra_features\"]\n",
    "models = [model_full, model_no_similiarity_scores, model_no_tfidf, model_no_trec, model_no_similarity_or_tfidf, \\\n",
    "         model_no_similarity_or_trec, model_no_tfidf_or_trec, model_no_extra_features]\n",
    "file_names = [\"../models/logreg_\" + name + \".pickle\" for name in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/logreg_all_features.pickle',\n",
       " '../models/logreg_no_similarity_scores.pickle',\n",
       " '../models/logreg_no_tfidf.pickle',\n",
       " '../models/logreg_no_trec.pickle',\n",
       " '../models/logreg_no_similarity_or_tfidf.pickle',\n",
       " '../models/logreg_no_similarity_or_trec.pickle',\n",
       " '../models/logreg_no_tfidf_or_trec.pickle',\n",
       " '../models/logreg_no_extra_features.pickle']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in zip(file_names, models):\n",
    "    with open(i[0], 'wb') as handle:\n",
    "        pkl.dump(i[1], handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing it out\n",
    "test = pkl.load(open('../models/logreg_all_features.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=550, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "That's a wrap! Very lazy - I know. I just wanted to see how good my xgb models really are, relative to a more simple model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
