{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Average WordNet Distance\n",
    "\n",
    "[This paper]((https://www.aaai.org/Papers/AAAI/2006/AAAI06-123.pdf) describes a method for scoring the sematic difference of sentences using WordNet. \n",
    "\n",
    "The idea is a scoring scheme which looks at the average \"distance\" of the words in the two sentences.\n",
    "\n",
    "To calculate the distance between sentences $T_1$ and $T_2$, go through the words in $T_1$ and find the word which is \"closest\" to it in $T_2$. Average these distances across all the words in $T_1$. \n",
    "\n",
    "To get a symmetric scoring scheme (i.e $Similiarity(T_1,T_2) = Similarity(T_2,T_1)$, perform the same operation, but this time starting with $T_2$ and findint the most similar words in $T_1$ to each word. The paper also suggests the use of _IDF_ scores.\n",
    "\n",
    "The score can be summarized: (Mihalcea, Corley, Strapparava)\n",
    "\n",
    "$$\n",
    "Similarity(T_1,T_2) = \\frac{1}{2}( \\frac{\\sum_{w \\in T_1}MaxSimilarity(w, T_2)idf(w)}{\\sum_{w \\in T_1}idf(w)}\n",
    "+ \\frac{\\sum_{w \\in T_2}MaxSimilarity(w, T_1)idf(w)}{\\sum_{w \\in T_2}idf(w)})\n",
    "$$\n",
    "\n",
    "Where $Similarity(w, T_i)$ is the greatest similarity between a word $w$ and word in $T_i$, according to some similarity metric (with respect to WordNet). This is a heuristic for getting the semantic similarity of sentences. \n",
    "\n",
    "Note: word comparisons are limited to words of the same part of speech. Furthermore, each word is always assumed to be the most common sense of that word. \n",
    "\n",
    "As a start, I'll implement this idea without _IDF_ scores, using a variety of WordNet distance metrics. If time permits, I'll include Idf scores as well. \n",
    "\n",
    "**Note**: Much of this code is taken from [this great blog post!](http://nlpforhackers.io/wordnet-sentence-similarity/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_sample = data.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343027</th>\n",
       "      <td>343028</td>\n",
       "      <td>343029</td>\n",
       "      <td>471095</td>\n",
       "      <td>471096</td>\n",
       "      <td>Topics for presentation ?</td>\n",
       "      <td>What is the best topic for presentation in Eng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180801</th>\n",
       "      <td>180802</td>\n",
       "      <td>180802</td>\n",
       "      <td>277111</td>\n",
       "      <td>277112</td>\n",
       "      <td>What is a brief summary of Marilynne Robinson'...</td>\n",
       "      <td>What does one mean by might as well create an ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194338</th>\n",
       "      <td>194339</td>\n",
       "      <td>194339</td>\n",
       "      <td>294518</td>\n",
       "      <td>294519</td>\n",
       "      <td>What is the difference between the Oxford scho...</td>\n",
       "      <td>Where is Oxford Public School ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303182</th>\n",
       "      <td>303183</td>\n",
       "      <td>303184</td>\n",
       "      <td>426289</td>\n",
       "      <td>426290</td>\n",
       "      <td>Could rulers have rules in governing ?</td>\n",
       "      <td>Why is Super Mario Maker such a good , success...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295076</th>\n",
       "      <td>295077</td>\n",
       "      <td>295078</td>\n",
       "      <td>105925</td>\n",
       "      <td>60263</td>\n",
       "      <td>How can I loss 50 pounds of body weight in a h...</td>\n",
       "      <td>The best way for weight loss ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      id    qid1    qid2  \\\n",
       "343027      343028  343029  471095  471096   \n",
       "180801      180802  180802  277111  277112   \n",
       "194338      194339  194339  294518  294519   \n",
       "303182      303183  303184  426289  426290   \n",
       "295076      295077  295078  105925   60263   \n",
       "\n",
       "                                                question1  \\\n",
       "343027                         Topics for presentation ?    \n",
       "180801  What is a brief summary of Marilynne Robinson'...   \n",
       "194338  What is the difference between the Oxford scho...   \n",
       "303182            Could rulers have rules in governing ?    \n",
       "295076  How can I loss 50 pounds of body weight in a h...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "343027  What is the best topic for presentation in Eng...             0  \n",
       "180801  What does one mean by might as well create an ...             0  \n",
       "194338                   Where is Oxford Public School ?              0  \n",
       "303182  Why is Super Mario Maker such a good , success...             0  \n",
       "295076                    The best way for weight loss ?              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple POS tagging\n",
    "\n",
    "In the proposed algorithm, we should only compare words of the same POS category (nouns, verbs, adjectives or adverbs). \n",
    "\n",
    "Below is a function which produces these broad tags for tokenized words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Conert Penn POS tags to broad tags\n",
    "\n",
    "`pos_tag` by NLTK automatcially gives fine POS tags. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pretty', 'JJ'),\n",
       " ('sentence', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize(\"this is a pretty sentence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function brings them to more simple POS tags (courtesy of [bogdani](http://nlpforhackers.io/author/bogdani/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', None),\n",
       " ('is', 'v'),\n",
       " ('a', None),\n",
       " ('pretty', 'a'),\n",
       " ('sentence', 'n'),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test conversion\n",
    "[(word, penn_to_wn(tag)) for (word,tag) in pos_tag(word_tokenize(\"this is a pretty sentence.\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: only nounds, verbs, adjectives and adverbs are tagged. Here, the determiners and punctuations are tagged as `None`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get synsets\n",
    "\n",
    "Now we can get the synset of the most common sense of word, filtered by part of speech (again courtesy of [bogdani](http://nlpforhackers.io/author/bogdani/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the most common synset for a tagged word from WordNet. \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    "    try:\n",
    "        # get the first synset of the word in WordNet\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pretty', 'JJ'),\n",
       " ('sentence', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "ex = pos_tag(word_tokenize(\"this is a pretty sentence.\"))\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " Synset('be.v.01'),\n",
       " None,\n",
       " Synset('pretty.s.01'),\n",
       " Synset('sentence.n.01'),\n",
       " None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tagged_to_synset(word,tag) for (word,tag) in ex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sentence similarities\n",
    "\n",
    "Now, I'll define series of functions for finding the sentence similarity scores for pairs of sentences, using a variety of wordnet distance metrics. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Path similarity\n",
    "\n",
    "This score is the distance betweeen synsets in WordNet - through the hyponym/hypernym path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def path_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score1, count1, score2, count2 = 0.0, 0, 0.0, 0 \n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # isolate the part of speech \n",
    "        synset_pos = synset.pos()\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        best_score = max([synset.path_similarity(ss) for ss in synsets2 if ss.pos() == synset_pos])\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score1 += best_score\n",
    "            count1 += 1\n",
    "            \n",
    "    for synset in synsets1:\n",
    "        try:\n",
    "            # isolate the part of speech \n",
    "            synset_pos = synset.pos()\n",
    "            # Get the similarity value of the most similar word in the other sentence\n",
    "            best_score = max([synset.path_similarity(ss) for ss in synsets1 if ss.pos() == synset_pos])\n",
    "        except:\n",
    "            best_score = None\n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score2 += best_score\n",
    "            count2 += 1\n",
    " \n",
    "    # Average the values and add score from both sides to get symmetic distance\n",
    "    score = .5*(score1/count1 + score2/count2)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5932539682539683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_similarity(\"The Mona-Lisa is pretty overrated if you ask me\", \\\n",
    "                      \"I hope that it will not rain tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_similarity(\"Cats are beautiful animals.\", \"Dogs are awesome creatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584054834054834"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_similarity(\"Trump reverses ban on importing remains of African elephants killed as trophies\", \\\n",
    "                      \"Native American tribe bracing for Keystone pipeline leak impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Leacock-Chodorow Similarity\n",
    "\n",
    "This similarity score is similar to the path similarity, but also incorporates the depth of the word in the WordNet taxonomy. The deeper the taxonomy depth, the higher the similarity score.\n",
    "\n",
    "The intuition is that the deeper the word are in the tree, the longer the paths between them in genereal. The second factor counters this fact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lch_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score1, count1, score2, count2 = 0.0, 0, 0.0, 0 \n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # isolate the part of speech \n",
    "        synset_pos = synset.pos()\n",
    "        try:\n",
    "            # Get the similarity value of the most similar word in the other sentence\n",
    "            best_score = max([synset.lch_similarity(ss) for ss in synsets2 if ss.pos() == synset_pos])\n",
    "        except:\n",
    "            best_score = None\n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score1 += best_score\n",
    "            count1 += 1\n",
    "            \n",
    "    for synset in synsets2:\n",
    "        # isolate the part of speech \n",
    "        synset_pos = synset.pos()\n",
    "        try:\n",
    "            # Get the similarity value of the most similar word in the other sentence\n",
    "            best_score = max([synset.lch_similarity(ss) for ss in synsets1 if ss.pos() == synset_pos])\n",
    "        except:\n",
    "            best_score = None\n",
    "            \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score2 += best_score\n",
    "            count2 += 1\n",
    " \n",
    "    # Average the values and add score from both sides to get symmetic score\n",
    "    score = .5*(score1/count1 + score2/count2)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.42868502671942"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lch_similarity(\"Trump reverses ban on importing remains of African elephants killed as trophies\", \\\n",
    "                      \"Native American tribe bracing for Keystone pipeline leak impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Wu-Palmer Similarity\n",
    "\n",
    "This similarity score is \"based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wup_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score1, count1, score2, count2 = 0.0, 0, 0.0, 0 \n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        try:\n",
    "            # isolate the part of speech \n",
    "            synset_pos = synset.pos()\n",
    "            # Get the similarity value of the most similar word in the other sentence\n",
    "            best_score = max([synset.wup_similarity(ss) for ss in synsets2 if ss.pos() == synset_pos])\n",
    "        except:\n",
    "            best_score = None\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score1 += best_score\n",
    "            count1 += 1\n",
    "            \n",
    "    for synset in synsets1:\n",
    "        try:\n",
    "            # isolate the part of speech \n",
    "            synset_pos = synset.pos()\n",
    "            # Get the similarity value of the most similar word in the other sentence\n",
    "            best_score = max([synset.wup_similarity(ss) for ss in synsets1 if ss.pos() == synset_pos])\n",
    "        except:\n",
    "            best_score = None\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score2 += best_score\n",
    "            count2 += 1\n",
    " \n",
    "    # Average the values and add score from both sides to get symmetic distance\n",
    "    score = .5*(score1/count1 + score2/count2)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904763"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_similarity(\"Cats are beautiful animals.\", \"Dogs are awesome creatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655952380952381"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_similarity(\"The Mona-Lisa is pretty overrated if you ask me\", \\\n",
    "                      \"I hope that it will not rain tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6760551948051948"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_similarity(\"Trump reverses ban on importing remains of African elephants killed as trophies\", \\\n",
    "                      \"Native American tribe bracing for Keystone pipeline leak impact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8263888888888888"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_similarity(\"I like to study in the montreal area with my friends\", \\\n",
    "                      \"I like to study in New York with my buddies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145691    0.774854\n",
       "328960    0.839566\n",
       "56745     0.793651\n",
       "201812    0.958333\n",
       "116988    0.933333\n",
       "121810    0.966667\n",
       "364092    0.780769\n",
       "253334    0.919298\n",
       "211479    0.876374\n",
       "35407     0.940000\n",
       "3173      1.000000\n",
       "254688    0.928571\n",
       "12667     0.944444\n",
       "385782    0.955357\n",
       "232077    0.776313\n",
       "164801    0.950000\n",
       "356156    1.000000\n",
       "395874    0.940000\n",
       "330119    0.758303\n",
       "254893    0.740957\n",
       "361111    0.983333\n",
       "36251     0.860043\n",
       "339525    0.932692\n",
       "13258     0.955556\n",
       "207535    0.937500\n",
       "232508    0.802778\n",
       "41162     0.920192\n",
       "157675    1.000000\n",
       "35167     1.000000\n",
       "179388    0.723334\n",
       "            ...   \n",
       "13550     0.642857\n",
       "146950    0.657862\n",
       "305762    1.000000\n",
       "401878    0.875000\n",
       "30538     0.929167\n",
       "185019    0.962500\n",
       "322550    0.864286\n",
       "356529    0.975000\n",
       "202260    0.794762\n",
       "169098    1.000000\n",
       "174406    0.797815\n",
       "149426    0.704637\n",
       "166594    0.925000\n",
       "320309    0.920139\n",
       "214412    0.814216\n",
       "307781    0.944444\n",
       "331025    0.822222\n",
       "366586    0.909057\n",
       "204536    0.942989\n",
       "249814    0.725000\n",
       "278501    1.000000\n",
       "227814    0.883333\n",
       "179673    0.781255\n",
       "32105     0.912281\n",
       "119675    0.880952\n",
       "391553    0.861355\n",
       "270438    0.814918\n",
       "358639    0.850893\n",
       "166910    0.838596\n",
       "119849    0.968750\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.apply(lambda x : wup_similarity(x['question1'],x['question2']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
