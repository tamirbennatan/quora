{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "# from nltk import word_tokenize, pos_tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Average WordNet Distance\n",
    "\n",
    "[This paper]((https://www.aaai.org/Papers/AAAI/2006/AAAI06-123.pdf) describes a method for scoring the sematic difference of sentences using WordNet. \n",
    "\n",
    "The idea is a scoring scheme which looks at the average \"distance\" of the words in the two sentences.\n",
    "\n",
    "To calculate the distance between sentences $T_1$ and $T_2$, go through the words in $T_1$ and find the word which is \"closest\" to it in $T_2$. Average these distances across all the words in $T_1$. \n",
    "\n",
    "To get a symmetric scoring scheme (i.e $Similiarity(T_1,T_2) = Similarity(T_2,T_1)$, perform the same operation, but this time starting with $T_2$ and findint the most similar words in $T_1$ to each word. The paper also suggests the use of _IDF_ scores.\n",
    "\n",
    "The score can be summarized: (Mihalcea, Corley, Strapparava)\n",
    "\n",
    "$$\n",
    "Similarity(T_1,T_2) = \\frac{1}{2}( \\frac{\\sum_{w \\in T_1}MaxSimilarity(w, T_2)idf(w)}{\\sum_{w \\in T_1}idf(w)}\n",
    "+ \\frac{\\sum_{w \\in T_2}MaxSimilarity(w, T_1)idf(w)}{\\sum_{w \\in T_2}idf(w)})\n",
    "$$\n",
    "\n",
    "Where $Similarity(w, T_i)$ is the greatest similarity between a word $w$ and word in $T_i$, according to some similarity metric (with respect to WordNet). This is a heuristic for getting the semantic similarity of sentences. \n",
    "\n",
    "Note: word comparisons are limited to words of the same part of speech. Furthermore, each word is always assumed to be the most common sense of that word. \n",
    "\n",
    "As a start, I'll implement this idea without _IDF_ scores, using a variety of WordNet distance metrics. If time permits, I'll include Idf scores as well. \n",
    "\n",
    "**Note**: Much of this code is taken from [this great blog post!](http://nlpforhackers.io/wordnet-sentence-similarity/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_sample = data.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343027</th>\n",
       "      <td>343028</td>\n",
       "      <td>343029</td>\n",
       "      <td>471095</td>\n",
       "      <td>471096</td>\n",
       "      <td>Topics for presentation ?</td>\n",
       "      <td>What is the best topic for presentation in Eng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180801</th>\n",
       "      <td>180802</td>\n",
       "      <td>180802</td>\n",
       "      <td>277111</td>\n",
       "      <td>277112</td>\n",
       "      <td>What is a brief summary of Marilynne Robinson'...</td>\n",
       "      <td>What does one mean by might as well create an ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194338</th>\n",
       "      <td>194339</td>\n",
       "      <td>194339</td>\n",
       "      <td>294518</td>\n",
       "      <td>294519</td>\n",
       "      <td>What is the difference between the Oxford scho...</td>\n",
       "      <td>Where is Oxford Public School ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303182</th>\n",
       "      <td>303183</td>\n",
       "      <td>303184</td>\n",
       "      <td>426289</td>\n",
       "      <td>426290</td>\n",
       "      <td>Could rulers have rules in governing ?</td>\n",
       "      <td>Why is Super Mario Maker such a good , success...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295076</th>\n",
       "      <td>295077</td>\n",
       "      <td>295078</td>\n",
       "      <td>105925</td>\n",
       "      <td>60263</td>\n",
       "      <td>How can I loss 50 pounds of body weight in a h...</td>\n",
       "      <td>The best way for weight loss ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      id    qid1    qid2  \\\n",
       "343027      343028  343029  471095  471096   \n",
       "180801      180802  180802  277111  277112   \n",
       "194338      194339  194339  294518  294519   \n",
       "303182      303183  303184  426289  426290   \n",
       "295076      295077  295078  105925   60263   \n",
       "\n",
       "                                                question1  \\\n",
       "343027                         Topics for presentation ?    \n",
       "180801  What is a brief summary of Marilynne Robinson'...   \n",
       "194338  What is the difference between the Oxford scho...   \n",
       "303182            Could rulers have rules in governing ?    \n",
       "295076  How can I loss 50 pounds of body weight in a h...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "343027  What is the best topic for presentation in Eng...             0  \n",
       "180801  What does one mean by might as well create an ...             0  \n",
       "194338                   Where is Oxford Public School ?              0  \n",
       "303182  Why is Super Mario Maker such a good , success...             0  \n",
       "295076                    The best way for weight loss ?              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple POS tagging\n",
    "\n",
    "In the proposed algorithm, we should only compare words of the same POS category (nouns, verbs, adjectives or adverbs). \n",
    "\n",
    "Below is a function which produces these broad tags for tokenized words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Conert Penn POS tags to broad tags\n",
    "\n",
    "`pos_tag` by NLTK automatcially gives fine POS tags. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pretty', 'JJ'),\n",
       " ('sentence', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize(\"this is a pretty sentence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function brings them to more simple POS tags (courtesy of [bogdani](http://nlpforhackers.io/author/bogdani/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', None),\n",
       " ('is', 'v'),\n",
       " ('a', None),\n",
       " ('pretty', 'a'),\n",
       " ('sentence', 'n'),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test conversion\n",
    "[(word, penn_to_wn(tag)) for (word,tag) in pos_tag(word_tokenize(\"this is a pretty sentence.\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: only nounds, verbs, adjectives and adverbs are tagged. Here, the determiners and punctuations are tagged as `None`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get synsets\n",
    "\n",
    "Now we can get the synset of the most common sense of word, filtered by part of speech (again courtesy of [bogdani](http://nlpforhackers.io/author/bogdani/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the most common synset for a tagged word from WordNet. \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    "    try:\n",
    "        # get the first synset of the word in WordNet\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pretty', 'JJ'),\n",
       " ('sentence', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "ex = pos_tag(word_tokenize(\"this is a pretty sentence.\"))\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " Synset('be.v.01'),\n",
       " None,\n",
       " Synset('pretty.s.01'),\n",
       " Synset('sentence.n.01'),\n",
       " None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tagged_to_synset(word,tag) for (word,tag) in ex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sentence similarities\n",
    "\n",
    "Now, I'll define series of functions for finding the sentence similarity scores for pairs of sentences, using a variety of wordnet distance metrics. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Path similarity\n",
    "\n",
    "This score is the distance betweeen synsets in WordNet - through the hyponym/hypernym path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def path_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score1, count1, score2, count2 = 0.0, 0, 0.0, 0 \n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        best_score = max([synset.path_similarity(ss) for ss in synsets2])\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score1 += best_score\n",
    "            count1 += 1\n",
    "            \n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        best_score = max([synset.path_similarity(ss) for ss in synsets1])\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score2 += best_score\n",
    "            count2 += 1\n",
    " \n",
    "    # Average the values and add score from both sides to get symmetic distance\n",
    "    score = .5*(score1/count1 + score2/count2)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166666666666667"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_similarity(\"The Mona-Lisa is pretty overrated if you ask me\", \\\n",
    "                      \"I hope that it will not rain tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_similarity(\"Cats are beautiful animals.\", \"Dogs are awesome creatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584054834054834"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_similarity(\"Trump reverses ban on importing remains of African elephants killed as trophies\", \\\n",
    "                      \"Native American tribe bracing for Keystone pipeline leak impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Leacock-Chodorow Similarity\n",
    "\n",
    "This similarity score is similar to the path similarity, but also incorporates the depth of the word in the WordNet taxonomy. The deeper the taxonomy depth, the higher the similarity score.\n",
    "\n",
    "The intuition is that the deeper the word are in the tree, the longer the paths between them in genereal. The second factor counters this fact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lch_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score1, count1, score2, count2 = 0.0, 0, 0.0, 0 \n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # isolate the part of speech \n",
    "        synset_pos = synset.pos()\n",
    "        try:\n",
    "            # Get the similarity value of the most similar word in the other sentence\n",
    "            best_score = max([synset.lch_similarity(ss) for ss in synsets2 if ss.pos() == synset_pos])\n",
    "        except:\n",
    "            best_score = None\n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score1 += best_score\n",
    "            count1 += 1\n",
    "            \n",
    "    for synset in synsets2:\n",
    "        # isolate the part of speech \n",
    "        synset_pos = synset.pos()\n",
    "        try:\n",
    "            # Get the similarity value of the most similar word in the other sentence\n",
    "            best_score = max([synset.lch_similarity(ss) for ss in synsets1 if ss.pos() == synset_pos])\n",
    "        except:\n",
    "            best_score = None\n",
    "            \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score2 += best_score\n",
    "            count2 += 1\n",
    " \n",
    "    # Average the values and add score from both sides to get symmetic score\n",
    "    score = .5*(score1/count1 + score2/count2)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.42868502671942"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lch_similarity(\"Trump reverses ban on importing remains of African elephants killed as trophies\", \\\n",
    "                      \"Native American tribe bracing for Keystone pipeline leak impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Wu-Palmer Similarity\n",
    "\n",
    "This similarity score is \"based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wup_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score1, count1, score2, count2 = 0.0, 0, 0.0, 0 \n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        best_score = max([synset.wup_similarity(ss) for ss in synsets2])\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score1 += best_score\n",
    "            count1 += 1\n",
    "            \n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        best_score = max([synset.wup_similarity(ss) for ss in synsets1])\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score2 += best_score\n",
    "            count2 += 1\n",
    " \n",
    "    # Average the values and add score from both sides to get symmetic distance\n",
    "    score = .5*(score1/count1 + score2/count2)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904763"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_similarity(\"Cats are beautiful animals.\", \"Dogs are awesome creatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6865079365079365"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_similarity(\"The Mona-Lisa is pretty overrated if you ask me\", \\\n",
    "                      \"I hope that it will not rain tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7007575757575758"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_similarity(\"Trump reverses ban on importing remains of African elephants killed as trophies\", \\\n",
    "                      \"Native American tribe bracing for Keystone pipeline leak impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Including IDF scores\n",
    "\n",
    "I've downloaded the freuency counts of the 100,000 most common words of the COCA corpus (Corpus of Contemporary American English). \n",
    "\n",
    "I'll use these to compte Idf weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 Load the COCA frequency set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coca = pd.read_excel(\"../data/100k_samples.xlsx\", sheetname=\"Rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_old</th>\n",
       "      <th>LINKS</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>PoS</th>\n",
       "      <th>CAPS</th>\n",
       "      <th>US/UK</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>coca_mag.3</th>\n",
       "      <th>coca_news.3</th>\n",
       "      <th>coca_acad.3</th>\n",
       "      <th>bnc_spok.3</th>\n",
       "      <th>bnc_fic.3</th>\n",
       "      <th>bnc_mag.3</th>\n",
       "      <th>bnc_news.3</th>\n",
       "      <th>bnc_noAc.3</th>\n",
       "      <th>bnc_acad.3</th>\n",
       "      <th>bnc_misc.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>at</td>\n",
       "      <td>0.105560</td>\n",
       "      <td></td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>53139</td>\n",
       "      <td>56903</td>\n",
       "      <td>21223</td>\n",
       "      <td>904</td>\n",
       "      <td>463</td>\n",
       "      <td>210</td>\n",
       "      <td>518</td>\n",
       "      <td>533</td>\n",
       "      <td>501</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>even</td>\n",
       "      <td>even</td>\n",
       "      <td>rr</td>\n",
       "      <td>0.163551</td>\n",
       "      <td></td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>34921</td>\n",
       "      <td>35790</td>\n",
       "      <td>15471</td>\n",
       "      <td>678</td>\n",
       "      <td>437</td>\n",
       "      <td>210</td>\n",
       "      <td>443</td>\n",
       "      <td>515</td>\n",
       "      <td>453</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212</td>\n",
       "      <td>200</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>men</td>\n",
       "      <td>man</td>\n",
       "      <td>nn2</td>\n",
       "      <td>0.081615</td>\n",
       "      <td></td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>12331</td>\n",
       "      <td>13299</td>\n",
       "      <td>5963</td>\n",
       "      <td>381</td>\n",
       "      <td>440</td>\n",
       "      <td>178</td>\n",
       "      <td>345</td>\n",
       "      <td>357</td>\n",
       "      <td>295</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>312</td>\n",
       "      <td>300</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>least</td>\n",
       "      <td>least</td>\n",
       "      <td>rr</td>\n",
       "      <td>0.004856</td>\n",
       "      <td></td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>17817</td>\n",
       "      <td>19379</td>\n",
       "      <td>11228</td>\n",
       "      <td>510</td>\n",
       "      <td>400</td>\n",
       "      <td>200</td>\n",
       "      <td>378</td>\n",
       "      <td>494</td>\n",
       "      <td>450</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>400</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>police</td>\n",
       "      <td>police</td>\n",
       "      <td>nn2</td>\n",
       "      <td>0.176128</td>\n",
       "      <td></td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>3656</td>\n",
       "      <td>9182</td>\n",
       "      <td>2063</td>\n",
       "      <td>206</td>\n",
       "      <td>306</td>\n",
       "      <td>130</td>\n",
       "      <td>302</td>\n",
       "      <td>235</td>\n",
       "      <td>202</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  ID_old LINKS Unnamed: 3    word   lemma  PoS      CAPS US/UK  \\\n",
       "0    1       1     C          K     the     the   at  0.105560         \n",
       "1  110     100     C          K    even    even   rr  0.163551         \n",
       "2  212     200     C          K     men     man  nn2  0.081615         \n",
       "3  312     300     C          K   least   least   rr  0.004856         \n",
       "4  412     400     C          K  police  police  nn2  0.176128         \n",
       "\n",
       "  Unnamed: 9     ...      coca_mag.3  coca_news.3  coca_acad.3  bnc_spok.3  \\\n",
       "0          @     ...           53139        56903        21223         904   \n",
       "1          @     ...           34921        35790        15471         678   \n",
       "2          @     ...           12331        13299         5963         381   \n",
       "3          @     ...           17817        19379        11228         510   \n",
       "4          @     ...            3656         9182         2063         206   \n",
       "\n",
       "   bnc_fic.3  bnc_mag.3  bnc_news.3  bnc_noAc.3  bnc_acad.3  bnc_misc.3  \n",
       "0        463        210         518         533         501         916  \n",
       "1        437        210         443         515         453         794  \n",
       "2        440        178         345         357         295         530  \n",
       "3        400        200         378         494         450         713  \n",
       "4        306        130         302         235         202         326  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         u'ID',      u'ID_old',       u'LINKS',  u'Unnamed: 3',\n",
       "              u'word',       u'lemma',         u'PoS',        u'CAPS',\n",
       "             u'US/UK',  u'Unnamed: 9',        u'freq',        u'COCA',\n",
       "               u'BNC',        u'SOAP',     u'1950-89',     u'1900-49',\n",
       "             u'1800s',   u'coca_spok',    u'coca_fic',    u'coca_mag',\n",
       "         u'coca_news',   u'coca_acad',    u'bnc_spok',     u'bnc_fic',\n",
       "           u'bnc_mag',    u'bnc_news',    u'bnc_noAc',    u'bnc_acad',\n",
       "          u'bnc_misc', u'Unnamed: 29',      u'COCA.1',       u'BNC.1',\n",
       "            u'SOAP.1',   u'1950-89.1',   u'1900-49.1',     u'1800s.1',\n",
       "       u'coca_spok.1',  u'coca_fic.1',  u'coca_mag.1', u'coca_news.1',\n",
       "       u'coca_acad.1',  u'bnc_spok.1',   u'bnc_fic.1',   u'bnc_mag.1',\n",
       "        u'bnc_news.1',  u'bnc_noAc.1',  u'bnc_acad.1',  u'bnc_misc.1',\n",
       "       u'Unnamed: 48',       u'BNC.2',      u'SOAP.2',   u'1950-89.2',\n",
       "         u'1900-49.2',     u'1800s.2', u'coca_spok.2',  u'coca_fic.2',\n",
       "        u'coca_mag.2', u'coca_news.2', u'coca_acad.2',  u'bnc_spok.2',\n",
       "         u'bnc_fic.2',   u'bnc_mag.2',  u'bnc_news.2',  u'bnc_noAc.2',\n",
       "        u'bnc_acad.2',  u'bnc_misc.2', u'Unnamed: 66',      u'COCA.2',\n",
       "             u'BNC.3',      u'SOAP.3',   u'1950-89.3',   u'1900-49.3',\n",
       "           u'1800s.3', u'coca_spok.3',  u'coca_fic.3',  u'coca_mag.3',\n",
       "       u'coca_news.3', u'coca_acad.3',  u'bnc_spok.3',   u'bnc_fic.3',\n",
       "         u'bnc_mag.3',  u'bnc_news.3',  u'bnc_noAc.3',  u'bnc_acad.3',\n",
       "        u'bnc_misc.3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Build a psuedo-IDF dictionary. \n",
    "\n",
    "What we're interested in is the IDF scores for the lemmas. I'll store this in a dictionary, for later access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>25131726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>even</td>\n",
       "      <td>415055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man</td>\n",
       "      <td>177630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>least</td>\n",
       "      <td>132652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>police</td>\n",
       "      <td>99926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lemma      freq\n",
       "0     the  25131726\n",
       "1    even    415055\n",
       "2     man    177630\n",
       "3   least    132652\n",
       "4  police     99926"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns I'm interested in \n",
    "coca[[\"lemma\", \"freq\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the formula for the idf score is: \n",
    "$$\n",
    "idf(w) = \\log(\\frac{1}{\\text{# of documents with the word w}})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
